{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PreProcess.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Oilb7zalJUXX"},"source":["import sys\n","sys.path.insert(0,'content/drive/MyDrive/MotorImagery-master')\n","import IPython"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EhGhdyvqQSOl","executionInfo":{"status":"ok","timestamp":1652897490937,"user_tz":420,"elapsed":9364,"user":{"displayName":"Capstone TeamJ","userId":"00861298733219114905"}},"outputId":"19cc4ceb-f45b-4e7c-e9c5-49026314ec41"},"source":["!pip install BCI2kReader==0.32.dev0"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting BCI2kReader==0.32.dev0\n","  Downloading BCI2kReader-0.32.dev0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from BCI2kReader==0.32.dev0) (1.21.6)\n","Installing collected packages: BCI2kReader\n","Successfully installed BCI2kReader-0.32.dev0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FVyimJRhQVeI","executionInfo":{"status":"ok","timestamp":1652935216486,"user_tz":420,"elapsed":17346,"user":{"displayName":"Capstone TeamJ","userId":"00861298733219114905"}},"outputId":"bf5b207b-9bc4-4c76-d8b4-eb52319061bb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"NSsXUTWWMypM"},"source":["'''\n","Functions for preprocessing raw .mat files\n","'''\n","\n","import numpy as np\n","import scipy.signal as sig\n","import scipy.io as scio\n","import pandas as pd\n","\n","\n","def unravel_matfile(file):\n","    '''\n","    Unravels data from .mat files produced by LoadMat.m\n","    '''\n","    train = file['train']\n","    HDRtrain=(file['HDRtrain'])\n","    val_t= HDRtrain[0,0]\n","    Event= (val_t['EVENT'])\n","    typtrain = Event['TYP']\n","    postrain = Event['POS']\n","    durtrain = Event['DUR']\n","    \n","    test = file['eval']\n","    HDReval=(file['HDReval'])\n","    val_e= HDReval[0,0]\n","    Event= (val_e['EVENT'])\n","    typtest = Event['TYP']\n","    postest = Event['POS']\n","    durtest = Event['DUR']\n","\n","    return [train, typtrain, postrain, durtrain]\n","\n","\n","def remove_eog(data):\n","    '''\n","    Removes EOG channels (last 3 channels)\n","    '''\n","    return data[:, :22]\n","\n","\n","def replace_nans(data):\n","    '''\n","    Each trial is separated by either 100 NaNs or 100 of the negative\n","    maximum value of the channel\n","    Replace these with the avg value of the channel\n","    '''\n","    for i in range(data.shape[1]):\n","        this_chan = data[:, i]\n","        data[:, i] = np.where(this_chan == np.min(this_chan), np.nan, this_chan)\n","        mask = np.isnan(data[:, i])\n","        chan_mean = np.nanmean(data[:, i])\n","        data[mask, i] = chan_mean \n","    return data\n","\n","\n","def to_mv(data):\n","    '''\n","    Converts v to mV for numerical stability\n","    '''\n","    return data * 1e6\n","\n","\n","def exponential_standardize(data, alpha=0.001, init_block_size=1000, eps=1e-4):\n","    '''\n","    This function applies an exponential moving window standardization to the data\n","    Set first 1000 mean and variance values to the mean and variance of the first 1000 samples\n","    Computes exponential moving means and variances to standardize data\n","    Returns channel-wise exponential smooothing with decay factor alpha\n","    \n","    data: (num_samples, num_channels)\n","    returns: (num_samples, num_channels)\n","    '''\n","    \n","    df = pd.DataFrame(data)\n","    meaned = df.ewm(alpha=alpha).mean()\n","    demeaned = df - meaned\n","    squared = demeaned * demeaned\n","    square_ewmed = squared.ewm(alpha=alpha).mean()\n","    standardized = demeaned / np.maximum(eps, np.sqrt(np.array(square_ewmed)))\n","    standardized = np.array(standardized)\n","    if init_block_size is not None:\n","        i_time_axis = 0\n","        init_mean = np.mean(\n","            data[0:init_block_size], axis=i_time_axis, keepdims=True\n","        )\n","        init_std = np.std(\n","            data[0:init_block_size], axis=i_time_axis, keepdims=True\n","        )\n","        init_block_standardized = (\n","                                          data[0:init_block_size] - init_mean\n","                                  ) / np.maximum(eps, init_std)\n","        standardized[0:init_block_size] = init_block_standardized  \n","    return standardized\n","\n","\n","def bandpass_filt(data, lowcut=1.0, highcut=40.0, fs=250.0, order=3, filter_type=\"filtfilt\", padlen=None):\n","    '''\n","    Bandpass filter  \n","    '''\n","    nyq = 0.5 * fs\n","    low = lowcut / nyq\n","    high = highcut / nyq\n","    b, a = sig.butter(order, [low, high], btype='band')\n","\n","    data = data.T\n","    if filter_type == \"filtfilt\":\n","        filtered_data = sig.filtfilt(b, a, data)\n","    else:\n","        filtered_data = sig.lfilter(b, a, data)  \n","    \n","    return filtered_data.T\n","\n","\n","def preprocess(data):\n","    '''\n","    Performs all preprocessing steps\n","    '''\n","    data = remove_eog(data)\n","    data = replace_nans(data)\n","    data = to_mv(data)\n","    \n","    data = bandpass_filt(data)\n","    data = exponential_standardize(data)\n","    return data\n","\n","def preprocess2(data):\n","    '''\n","    Performs all preprocessing steps\n","    '''\n","    data = to_mv(data)\n","    data = bandpass_filt(data)\n","    data = exponential_standardize(data)\n","    return data\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"29bbRe_cMU-w"},"source":["import numpy as np\n","import scipy.signal as sig\n","import scipy.io as scio\n","import pandas as pd\n","\n","\n","def extract_trials(data, labels, starts, continuous=False, classes=[]):\n","    '''\n","    Extracts individual trials from continuous data (four class)\n","    \n","    data: (num_samples, num_channels)\n","    labels: list of trial labels\n","    starts: time sample of trial start\n","    continuous: if True, extract trials with rest\n","    classes: list of classes to extract, default is empty array to extract all four\n","             left_hand -> 769, right_hand -> 770, feet -> 771, tongue -> 772\n","    returns: X: (num_trials, num_samples, num_channels)\n","             y: (num_trials)\n","    ''' \n","    X = []\n","    y = []\n","    new_x=0\n","    reject = 1023\n","    \n","    trial_labels = [769, 770, 771, 772]\n","    \n","    \n","    dur = 1000 # duration of motor imagery task\n","    if continuous:\n","        rest = 500 # duration of rest before and after task\n","    else:\n","        rest = 0\n","    for i in np.arange(labels.shape[0]):\n","    \n","        # reject bad trials\n","        if ((i+1 != labels.shape[0]) and (labels[i+1] == reject)):\n","            continue\n","            \n","        # skip labels that are not labels we want to look at\n","        if len(classes) > 0:\n","            if labels[i] not in classes:\n","                continue\n","        \n","        \n","        label = labels[i]\n","        \n","        if (label in trial_labels):    \n","            new_x = data[int(starts[i]-1-rest):int(starts[i]-1+dur+rest)]\n","            \n","            if np.asarray(new_x).shape[0] == (dur + 2*rest):\n","                X.append(new_x)\n","                y.append(label - 769)   \n","\n","            \n","    return np.asarray(X),np.asarray(y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NoYnj-XGsj4_"},"source":["def extract_trials_new(data, labels, starts, continuous=False, classes=[]):\n","    '''\n","    Extracts individual trials from continuous data (four class)\n","    \n","    data: (num_samples, num_channels)\n","    labels: list of trial labels\n","    starts: time sample of trial start\n","    continuous: if True, extract trials with rest\n","    classes: list of classes to extract, default is empty array to extract all four\n","             left_hand -> 769, right_hand -> 770, feet -> 771, tongue -> 772\n","    returns: X: (num_trials, num_samples, num_channels)\n","             y: (num_trials)\n","    ''' \n","    X = []\n","    y = []\n","    new_x=0\n","    reject = 1023\n","    \n","    trial_labels = [1, 2, 3, 4]\n","    \n","    dur = 1000 # duration of motor imagery task\n","    if continuous:\n","        rest = 875 # duration of rest before and after task\n","    else:\n","        rest = 0\n","    for i in np.arange(labels.shape[0]):\n","    \n","        # reject bad trials\n","        # if ((i+1 != labels.shape[0]) and (labels[i+1] == reject)):\n","        #     continue\n","            \n","        # skip labels that are not labels we want to look at\n","        if len(classes) > 0:\n","            if labels[i] not in classes:\n","                continue\n","        \n","        \n","        label = labels[i]\n","        \n","        if (label in trial_labels):    \n","            new_x = data[int(starts[i]-1-rest):int(starts[i]-1+dur+rest)]\n","            \n","            if np.asarray(new_x).shape[0] == (dur + 2*rest):\n","                X.append(new_x)\n","                y.append(label - 1)  \n","    return np.asarray(X),np.asarray(y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vtRbCaSTQXMP"},"source":["\"\"\"This is for data collected by our team. Imports .dat files and convert to .npy format\"\"\"\n","from sklearn.model_selection import train_test_split\n","from BCI2kReader import BCI2kReader as b2k\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import svm \n","from sklearn.preprocessing import scale\n","from sklearn.decomposition import PCA\n","\n","fs = 256\n","num_channels = 32\n","\n","### Things to change for a run\n","start = 1\n","end = 6\n","window = True\n","random_state = None # Switch to None for shuffling (default)\n","window_len = [500]\n","\n","###\n","\n","if window == True:\n","  tot_samples = 750\n","else:\n","  tot_samples = 1000\n","\n","\n","# Look at transpose\n","\n","for j in range(start,end):\n","    if j < 10:\n","      data='/content/drive/MyDrive/MotorImagery-master/Data/CollectedData/ArdoWet/ArdoWetS001R0'+str(j)+'.dat'\n","    else:\n","      data='/content/drive/MyDrive/MotorImagery-master/Data/CollectedData/ArdoWet/ArdoWetS001R'+str(j)+'.dat'\n","    path='/content/drive/MyDrive/MotorImagery-master/Data/CollectedData/ArdoWet'\n","    #print(data)\n","    with b2k.BCI2kReader(data) as test:\n","        n=1 \n","        test.samplingrate\n","\n","        data = test.signals\n","        print(\"Pre transpose: \",data.shape)\n","        data = np.transpose(data)\n","        print(\"Post transpose: \",data.shape)\n","        # Post transpose matches shape of public dataset\n","\n","        states = test.states\n","        stimulusCode = states['StimulusCode'][0]\n","        #print(stimulusCode)\n","\n","        startIndeces = []\n","        endIndeces = []\n","        labels = []\n","\n","        midTrial = False\n","\n","        for i, val in enumerate(stimulusCode):\n","          if i == 0:\n","            continue\n","\n","\n","          if midTrial:\n","            if stimulusCode[i] == 0:\n","              endIndeces.append(i-1)\n","              midTrial = False\n","            continue\n","\n","          if stimulusCode[i-1] == 0 and stimulusCode[i]!=0:\n","            startIndeces.append([i])\n","            labels.append([stimulusCode[i]])\n","            midTrial = True\n","\n","        \n","        labels = np.array(labels)\n","        starts = np.array(startIndeces)\n","\n","        data = preprocess2(data)\n","      \n","\n","        print(\"Data shape: \",data.shape)\n","        print(\"Labels shape: \", labels.shape)\n","        print(\"Starts shape: \", starts.shape)\n","        \n","        if j == start:\n","          # Make trials\n","          X, y = extract_trials_new(data, labels, starts, continuous=False) \n","          print(\"X: \",X.shape)\n","        else:\n","          X_, y_ = extract_trials_new(data, labels, starts, continuous=False)\n","          X = np.concatenate((X,X_))\n","          y = np.concatenate((y,y_))\n","\n","\n","# Ensure X is shape (trials, samples, channels)\n","\n","trials, dim1, dim2 = X.shape\n","\n","\n","\n","if dim1 == num_channels:\n","    X = np.reshape(X, (trials, dim2, dim1))\n","\n","\n","print(\"X shape: !\",X.shape)\n","# Applies moving window to single trial\n","# stride of 50% of window length\n","\n","if window == True:\n","  for L in window_len: #only our 500 window\n","\n","      # determines starting sample of each window\n","      if L == 750:\n","          starts = [0, 100, 250]\n","      else:\n","          starts = [0,250,500]\n","          print(\"starts: \", starts)\n","          \n","    \n","      # take window\n","      for i in starts:\n","          windowed_X = X[:,i:i+L,:]\n","          print(\"winXshape: \",windowed_X.shape)\n","          print(\"i: \",i)\n","\n","          \n","          # split into train-val-test\n","          X_trainval, X_test, y_trainval, y_test = train_test_split(windowed_X, y, test_size=0.2, random_state=random_state)\n","          X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25, random_state=random_state)\n","          print(window_len[0])\n","          if window_len[0]==500:\n","          # save dataset\n","            print(\"Subject: \", str(n), \" window: \", str(L), \" start: \", str(i))\n","            print()\n","            np.save(path+'/500Windowed/'+str(i)+'/X_train_'+str(n)+'.npy', X_train)\n","            np.save(path+'/500Windowed/'+str(i)+'/y_train_'+str(n)+'.npy', y_train)\n","            np.save(path+'/500Windowed/'+str(i)+'/X_val_'+str(n)+'.npy', X_val)\n","            np.save(path+'/500Windowed/'+str(i)+'/y_val_'+str(n)+'.npy', y_val)\n","            np.save(path+'/500Windowed/'+str(i)+'/X_test_'+str(n)+'.npy', X_test)\n","            np.save(path+'/500Windowed/'+str(i)+'/y_test_'+str(n)+'.npy', y_test)\n","          if window_len[0]==750:\n","          # save dataset\n","            print(\"Subject: \", str(n), \" window: \", str(L), \" start: \", str(i))\n","            print()\n","            np.save(path+'/750Windowed/'+str(i)+'/X_train_'+str(n)+'.npy', X_train)\n","            np.save(path+'/750Windowed/'+str(i)+'/y_train_'+str(n)+'.npy', y_train)\n","            np.save(path+'/750Windowed/'+str(i)+'/X_val_'+str(n)+'.npy', X_val)\n","            np.save(path+'/750Windowed/'+str(i)+'/y_val_'+str(n)+'.npy', y_val)\n","            np.save(path+'/750Windowed/'+str(i)+'/X_test_'+str(n)+'.npy', X_test)\n","            np.save(path+'/750Windowed/'+str(i)+'/y_test_'+str(n)+'.npy', y_test)\n","else:\n","    # split into train-val-test\n","    X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.25,random_state=random_state)\n","    X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25,random_state=random_state)\n","        \n","\n","    # save dataset\n","    print(\"Subject: \", str(i), \" window: None\")\n","    print()\n","    np.save(path+'/NoWindow/X_train_'+str(n)+'.npy', X_train)\n","    np.save(path+'/NoWindow/y_train_'+str(n)+'.npy', y_train)\n","    np.save(path+'/NoWindow/X_val_'+str(n)+'.npy', X_val)\n","    np.save(path+'/NoWindow/y_val_'+str(n)+'.npy', y_val)\n","    np.save(path+'/NoWindow/X_test_'+str(n)+'.npy', X_test)\n","    np.save(path+'/NoWindow/y_test_'+str(n)+'.npy', y_test)\n","\n","print(\"success\")\n","print()\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PuHQP_wx4hYZ"},"source":["\"\"\"This is for data made publicly available online. Imports .mat files and convert to .npy format\"\"\"\n","from sklearn.model_selection import train_test_split \n","import matplotlib.pyplot as plt\n","import os\n","\n","np.random.seed(0)\n","\n","window_len = [500]\n","path = \"/content/drive/MyDrive/MotorImagery-master/Data/PublicData\"\n","num_subjects = 9\n","#subject_id = np.arange(num_subjects)\n","subject_id = [4]\n","fs = 250\n","num_channels = 22\n","tot_samples = 1000\n","\n","for n in subject_id:\n","       \n","    #Load raw data from .mat files\n","    matdata = unravel_matfile(scio.loadmat(\"/content/drive/MyDrive/MotorImagery-master/Data/Mat_Files/subject0\"+str(n+1)+'.mat') )\n","    data = matdata[0]\n","    labels = matdata[1]\n","    starts = matdata[2]\n","\n","\n","\n","    data = preprocess(data)\n","    print(data.shape)\n","\n","\n","    #labels=np.array(labels)\n","    labels=labels[0][0]\n","    #starts=np.array(starts)\n","    starts=starts[0][0]\n","\n","    \n","    \n","    # Make trials\n","    X, y = extract_trials(data, labels, starts, continuous=False) \n","    print(X.shape)\n","    print(y.shape)\n","\n","    # Ensure X is shape (trials, samples, channels)\n","    trials, dim1, dim2 = X.shape\n","    if dim1 == num_channels:\n","        X = np.reshape(X, (trials, dim2, dim1))\n","        \n","    \n","    # Applies moving window to continuous trial\n","    # Take only first 50% of window length\n","    window = True\n","\n","    if window == True:\n","      for L in window_len: #only our 500 window\n","\n","          # determines starting sample of each window\n","          if L == 750:\n","              starts = [0, 250]\n","          else:\n","              starts = np.arange(0, tot_samples-L+1, int(L))\n","              print(\"starts: \", starts)\n","            \n","       \n","          # take window\n","          for i in starts:\n","              windowed_X = X[:,i:i+L,:]\n","              print(\"winXshape: \",windowed_X.shape)\n","              print(\"i: \",i)\n","\n","            \n","              # split into train-val-test\n","              X_trainval, X_test, y_trainval, y_test = train_test_split(windowed_X, y, test_size=0.2)\n","              X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25)\n","            \n","\n","              # save dataset\n","              print(\"Subject: \", str(n), \" window: \", str(L), \" start: \", str(i))\n","              print()\n","              np.save(path+'/500Windowed/'+str(i)+'/X_train_'+str(n)+'.npy', X_train)\n","              np.save(path+'/500Windowed/'+str(i)+'/y_train_'+str(n)+'.npy', y_train)\n","              np.save(path+'/500Windowed/'+str(i)+'/X_val_'+str(n)+'.npy', X_val)\n","              np.save(path+'/500Windowed/'+str(i)+'/y_val_'+str(n)+'.npy', y_val)\n","              np.save(path+'/500Windowed/'+str(i)+'/X_test_'+str(n)+'.npy', X_test)\n","              np.save(path+'/500Windowed/'+str(i)+'/y_test_'+str(n)+'.npy', y_test)\n","    else:\n","      # split into train-val-test\n","        X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2)\n","        X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.25)\n","            \n","\n","        # save dataset\n","        print(\"Subject: \", str(n), \" window: None\")\n","        print()\n","        np.save(path+'/NoWindow/X_train_'+str(n)+'.npy', X_train)\n","        np.save(path+'/NoWindow/y_train_'+str(n)+'.npy', y_train)\n","        np.save(path+'/NoWindow/X_val_'+str(n)+'.npy', X_val)\n","        np.save(path+'/NoWindow/y_val_'+str(n)+'.npy', y_val)\n","        np.save(path+'/NoWindow/X_test_'+str(n)+'.npy', X_test)\n","        np.save(path+'/NoWindow/y_test_'+str(n)+'.npy', y_test)\n","\n","\n","    print(\"success\")\n","    print()  \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uGfnKP3jdG_p"},"execution_count":null,"outputs":[]}]}